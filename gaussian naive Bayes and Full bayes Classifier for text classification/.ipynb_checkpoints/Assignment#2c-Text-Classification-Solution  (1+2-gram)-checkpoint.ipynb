{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0721764a-2ee0-45f9-b8d0-3584e88fce70"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Assignment No 2c\n",
    "\n",
    "Text Classification (Sentiment Analysis) Using Bayes Rule \n",
    "==============\n",
    "*Sibt ul Hussain*\n",
    "\n",
    "## Goal\n",
    "\n",
    "Your goal in this part of assigment is to implement a Naive Bayes Multinomial classifier using  bag of words model for the classification of text (movie reviews) into different categories..\n",
    "\n",
    "**Note** Please note that you are allowed to use only those libraries which we have discussed in the class, i.e. numpy, scipy, pandas.\n",
    "\n",
    "Once you have build and test the model on the provided dataset. You will use the learned techniques to compete in a [Kaggle](https://www.kaggle.com/c/word2vec-nlp-tutorial) competition and report your final score and leaderboard ranking to get full credit.\n",
    "\n",
    "For final submission attach the screen-shot of the leader-board with your score.\n",
    "\n",
    "## Submission Instructions\n",
    "You are required to submit the original notebook file on the Slate (with .ipynb extension), with complete set of outputs. Students failing to do so will get zero marks. \n",
    "\n",
    "*Please read each step carefully and understand it fully before proceeding with code writing*\n",
    "\n",
    "## Plagiarism\n",
    "Any form of plagiarism will not be tolerated and result in 0 marks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "33b0fb9a-4940-4251-9a82-44562ed9724d"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import scipy.stats\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "41bc7183ffc40d65a148fc72fb955046",
     "grade": false,
     "grade_id": "parse_string",
     "locked": false,
     "solution": true
    },
    "nbpresent": {
     "id": "0b1f3428-37ea-401c-9556-627e53402501"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import bs4\n",
    "\n",
    "def parse_string(string): \n",
    "    \"\"\"\"\n",
    "        Parse the input string and tokenize it using regular expressisons:\n",
    "        First clean the string such that it does not have any punctuation or number, it must only have a-z and A-Z.\n",
    "        Please note that while doing this, the spaces much not get disturbed, but in case of multiple spaces convert \n",
    "        them to one space.\n",
    "        Then convert the string to lower case and return its words as a list of strings.\n",
    "        \n",
    "        Example:\n",
    "        --------\n",
    "        Input :  computer scien_tist-s are,,,  the  rock__stars of tomorrow_ <cool>  ????\n",
    "        Output:  ['computer', 'scientists', 'are', 'the', 'rockstars', 'of', 'tomorrow']\n",
    "        \n",
    "        Parameters:\n",
    "        ----------\n",
    "        string: string to be parsed...\n",
    "        re: regular expression to be used for the tokenization.\n",
    "        \n",
    "        Returns:\n",
    "        ---------\n",
    "        list of tokens extracted from the string...\n",
    "    \"\"\"\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    return re.findall(r\"[A-Za-z]+\",(\"\".join(re.findall(r\"[A-Za-z ]+\",string))).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "a5035e3a9d5a9db47fdbafa62cc8a6a3",
     "grade": false,
     "grade_id": "parse_file",
     "locked": false,
     "solution": true
    },
    "nbpresent": {
     "id": "c7a1f399-97ec-4a5d-b8b0-c20a136f93b8"
    }
   },
   "outputs": [],
   "source": [
    "def parse_file(filename): # Parse a given file\n",
    "    \"\"\"\"\n",
    "        Parameters:\n",
    "        ----------\n",
    "        filename: name of text file to be read\n",
    "   \n",
    "        \n",
    "        Returns:\n",
    "        ---------\n",
    "        read file as raw string (with \\n, \\t, \\r, etc included)\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    return open(filename).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "6d2b49b37e798724777c6c429add90f1",
     "grade": false,
     "grade_id": "files_to_string",
     "locked": false,
     "solution": true
    },
    "nbpresent": {
     "id": "f4da4af7-6a5c-4674-a694-6097610f7271"
    }
   },
   "outputs": [],
   "source": [
    "def files_to_strings(X):\n",
    "    # YOUR CODE HERE\n",
    "        \n",
    "## Hint, you can use python dictionary or default dict for counting the words\n",
    "# or counter class from collections \n",
    "\n",
    "#TODO Complete this class for running the complete classifier... \n",
    "\n",
    "#You might need to define auxiliary classes for the complete algorithm..\n",
    "\n",
    "class NaiveBayes:\n",
    "    ''' Implements the Naive Bayes For Text Classification... '''\n",
    "    def __init__(self, classes):\n",
    "        self.classes=classes\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "       \n",
    "        \n",
    "    def addExample(self, x, y):\n",
    "        '''\n",
    "            Add example to corresponding class model ...\n",
    "            Input\n",
    "            ---------\n",
    "            x: example (list of words)\n",
    "            y: label...\n",
    "        '''\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "    def train(self, X, Y):\n",
    "        ''' Train the multiclass (or Binary) Bayes Rule using the given \n",
    "            X [m x d] data matrix and Y labels matrix\n",
    "            \n",
    "            Input:\n",
    "            ------\n",
    "            X: [m x d] a data matrix of m d-dimensional examples.\n",
    "            Y: [m x 1] a label vector.\n",
    "            \n",
    "            Returns:\n",
    "            -----------\n",
    "            Nothing\n",
    "            '''\n",
    "        # YOUR CODE HERE\n",
    "        \n",
    "        self.total=len(Y)#total length of DataSet\n",
    "        self.uniquelabels=np.unique(Y)\n",
    "        classes=[X[(Y==label)] for label in self.uniquelabels]\n",
    "        C1=np.array(classes[0],dtype=str)\n",
    "        C2=np.array(classes[1],dtype=str)\n",
    "        #print shape(C1)\n",
    "        C1=parse_string(\"\".join(C1.flatten()))\n",
    "        C2=parse_string(\"\".join(C2.flatten()))\n",
    "        self.bgofwordsC1=defaultdict(int)\n",
    "        self.bgofwordsC2=defaultdict(int)\n",
    "        self.bgofwords2GC1=defaultdict(int)\n",
    "        self.bgofwords2GC2=defaultdict(int)\n",
    "       \n",
    "        i=0\n",
    "        while(i<len(C1)-1):\n",
    "            self.bgofwordsC1[C1[i]]+=1\n",
    "            self.bgofwords2GC1[C1[i]+C1[i+1]]+=1\n",
    "            i+=1\n",
    "        self.bgofwordsC1[C1[i]]+=1\n",
    "        i=0\n",
    "        while(i<len(C2)-1):\n",
    "            self.bgofwordsC2[C2[i]]+=1\n",
    "            self.bgofwords2GC2[C2[i]+C2[i+1]]\n",
    "            i+=1\n",
    "        self.bgofwordsC2[C2[i]]+=1\n",
    "        self.totC1=len(C1)\n",
    "        self.totC2=len(C2)\n",
    "        self.tot2GC1=self.totC1-1\n",
    "        self.tot2GC2=self.totC2-1\n",
    "        self.total2G=self.tot2GC1+self.tot2GC2\n",
    "        self.total=self.totC1+self.totC2#total data of matrix\n",
    "        #print bgofwordsC1\n",
    "        #calculate the priors\n",
    "        self.pC1=np.log(self.totC1/(self.total*1.0))\n",
    "        self.pC2=np.log(self.totC2/(self.total*1.0))\n",
    "        self.p2GC1=np.log(self.tot2GC1/(self.total2G*1.0))\n",
    "        self.p2GC2=np.log(self.tot2GC2/(self.total2G*1.0))\n",
    "    def test(self, X):\n",
    "        \n",
    "        ''' Test the trained classifiers on the given set of examples \n",
    "        \n",
    "                   \n",
    "            Input:\n",
    "            ------\n",
    "            X: [m x d] a data matrix of m d-dimensional test examples.\n",
    "           \n",
    "            Returns:\n",
    "            -----------\n",
    "                pclass: the predicted class for each example, i.e. to which it belongs\n",
    "        '''\n",
    "        #nexamples, nfeatures=X.shape\n",
    "        #print nexamples,\" \",nfeatures  \n",
    "        # YOUR CODE HERE\n",
    "        totaluniquevalues= len(np.union1d(self.bgofwordsC1.keys(),self.bgofwordsC2.keys()))\n",
    "        totaluniquevalues2G= len(np.union1d(self.bgofwords2GC1.keys(),self.bgofwords2GC2.keys()))\n",
    "        if(np.ndim(X)==1):\n",
    "            X=np.reshape(X,(1,len(X)))\n",
    "        pclass=[\"\"]*len(X)\n",
    "        i=0\n",
    "        for review in X:\n",
    "            review=parse_string(\" \".join(review))\n",
    "            reviewbagofwards=defaultdict(int)\n",
    "            reviewbagofwards2G=defaultdict(int)\n",
    "            i=0\n",
    "            while(i<len(review)-1):\n",
    "                reviewbagofwards[review[i]]+=1\n",
    "                reviewbagofwards2G[review[i]+review[i+1]]\n",
    "                i+=1\n",
    "            reviewbagofwards[review[i]]+=1\n",
    "            likelihoodC1=0\n",
    "            likelihoodC2=0\n",
    "            likelihood2GC1=0\n",
    "            likelihood2GC2=0\n",
    "            #likelihood of all words in review\n",
    "            for word2G in reviewbagofwards2G.iterkeys():\n",
    "                likelihood2GC1+=np.log(((self.bgofwords2GC1[word2G]+1.0)/(totaluniquevalues2G+self.tot2GC1))**reviewbagofwards2G[word2G])\n",
    "                likelihood2GC2+=np.log(((self.bgofwords2GC2[word2G]+1.0)/(totaluniquevalues2G+self.tot2GC2))**reviewbagofwards2G[word2G])\n",
    "            for word in reviewbagofwards.iterkeys():    \n",
    "                likelihoodC1+=np.log(((self.bgofwordsC1[word]+1.0)/(totaluniquevalues+self.totC1))**reviewbagofwards[word])\n",
    "                likelihoodC2+=np.log(((self.bgofwordsC2[word]+1.0)/(totaluniquevalues+self.totC2))**reviewbagofwards[word])\n",
    "            #posterior probability\n",
    "            posC1=(likelihoodC1+self.pC1)+(likelihood2GC1+self.p2GC1)\n",
    "            posC2=(likelihoodC2+self.pC2)+(likelihood2GC2+self.p2GC2)\n",
    "            #print posC1,\"   \",posC2\n",
    "            if(posC1>posC2):\n",
    "                pclass[i]=self.uniquelabels[0]\n",
    "            else:\n",
    "                pclass[i]=self.uniquelabels[1]\n",
    "            i+=1\n",
    "            #likelihoodC1=np.array([np.log(((self.bgofwordsC1[x]+1.0)/self.)**reviewbagofwards[x]) for x in reviewbagofwards.iterkeys()])\n",
    "            #likelihoodC2=np.array([np.log(((self.bgofwordsC2[x]+1.0)/)**reviewbagofwards[x]) for x in reviewbagofwards.iterkeys()])  \n",
    "        return np.array(pclass)\n",
    "        \n",
    "    def predict(self, x):\n",
    "        '''\n",
    "            Predict the label of given input example...\n",
    "            \n",
    "            Input\n",
    "            ---------\n",
    "            x: example (list of words)\n",
    "            \n",
    "        '''\n",
    "        # YOUR CODE HERE\n",
    "        return (self.test(x))[0]\n",
    "    \"\"\"\n",
    "        Read an array (or list) of files where each file content is read in a string...\n",
    "        Input:\n",
    "        -------\n",
    "        X an array (or list) of file names\n",
    "        \n",
    "        Returns:\n",
    "        --------\n",
    "        X as a numpy array with each row containing a read string from the file...\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    readfiles=[parse_file(X[i]) for i in range(0,len(X),1)]\n",
    "    return np.array(readfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "96714a19700e62e9b60de218a6e81b58",
     "grade": true,
     "grade_id": "test_reading_and_parsing",
     "locked": true,
     "points": 2,
     "solution": false
    },
    "nbpresent": {
     "id": "8bfc4479-732e-4713-865c-6b358e0fe8da"
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal, assert_list_equal\n",
    "\n",
    "assert_list_equal(parse_string(\"computer scien_tist-s are,,,  the  rock__stars of tomorrow_  ????\"),\n",
    "        [u'computer', u'scientists', u'are', u'the', u'rockstars', u'of', u'tomorrow'], \"Incorrect cleanning\")\n",
    "\n",
    "\n",
    "strings = files_to_strings(np.array([\"./data/imdb1/neg/cv000_29416.txt\", \"./data/imdb1/pos/cv000_29590.txt\"]))\n",
    "with open(\"./data/imdb1/neg/cv000_29416.txt\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "assert_equal(strings[0], text, \"At first index should be text of first file\")\n",
    "assert_equal(strings.shape, (2,), \"Shape must be (2,) for two files in list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "4412e1df0ae5399bde4cfc7440cdc052",
     "grade": false,
     "grade_id": "classifier",
     "locked": false,
     "solution": true
    },
    "nbpresent": {
     "id": "40627bd6-9415-4f97-bf2b-e24b1371cd62"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "5753b5c5-90b7-4a3c-ab3d-cbcb4d956e22"
    },
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tools as t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d=defaultdict(int)\n",
    "d[\"hello\"]=10\n",
    "d[\"asif\"]=5\n",
    "d2=defaultdict(int)\n",
    "d2[\"hello\"]=10\n",
    "y=d.iterkeys()\n",
    "u=d2.iterkeys()\n",
    "for x in u:\n",
    "    print x\n",
    "    word=y.next()\n",
    "    print word,word,word\n",
    "print y.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "fcb102ee-6dcd-4b84-9fed-3bfc4cb7bc9d"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "tdir= \"./data/imdb1/\" # training dir...\n",
    "#load data, get list of files for each class...\n",
    "posfiles=t.get_files(tdir+'/pos','*',withpath=True)\n",
    "negfiles=t.get_files(tdir+'/neg','*',withpath=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "2ac1545d-a0c3-4b0f-87fe-ac7c523d34f5"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data Dimensions = (2000,)  Training labels dimensions= (2000,)\n"
     ]
    }
   ],
   "source": [
    "#generate training and testing data...\n",
    "plabels=['pos']*len(posfiles)\n",
    "nlabels=['neg']*len(posfiles)\n",
    "labels=np.concatenate((plabels,nlabels)) # concatenate the +ve and -ve labels\n",
    "tX=np.concatenate((posfiles,negfiles))\n",
    "print \"Training data Dimensions =\", tX.shape,\" Training labels dimensions=\", labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "244a98fd-7f59-4e40-b26a-9b7cdb766940"
    }
   },
   "outputs": [],
   "source": [
    "X=files_to_strings(tX) # read files and convert each file into set of strings and return an numpy array\n",
    "X = X.reshape((X.shape[0], 1))\n",
    "#Split the data into two halves training and test set...\n",
    "traindata,trainlabels,testdata,testlabels=t.split_data(X,labels)\n",
    "#Find the classes to train\n",
    "classes=np.unique(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "aee3ce96-c88a-4bc5-bc9f-aa58c355db55"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] training a classifier for following classes neg, pos\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list assignment index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-127-a3a4d1e034fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNaiveBayes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraindata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtrainlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpclasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpclasses\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mtestlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"[Info] Accuracy = {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-121-387e94bff314>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0;31m#print posC1,\"   \",posC2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposC1\u001b[0m\u001b[0;34m>\u001b[0m\u001b[0mposC2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m                 \u001b[0mpclass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniquelabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m                 \u001b[0mpclass\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muniquelabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list assignment index out of range"
     ]
    }
   ],
   "source": [
    "#Now build a Naive Bayes classifier and test it...\n",
    "print '[Info] training a classifier for following classes {}, {}'.format(classes[0],classes[1])\n",
    "nb=NaiveBayes(classes)\n",
    "nb.train(traindata,trainlabels)\n",
    "pclasses=nb.test(testdata)\n",
    "acc=np.sum(pclasses==testlabels)/float(testlabels.shape[0])\n",
    "print \"[Info] Accuracy = {}\".format(acc)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "1d77d1b6-b8e0-4c09-a484-27ff7c1ae1f6"
    }
   },
   "source": [
    "### Test Cells Start\n",
    "#### Do not Modify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "5822a32f567e3fb7e7f8515eacddec7d",
     "grade": true,
     "grade_id": "test_classifier_shapes",
     "locked": true,
     "points": 1,
     "solution": false
    },
    "nbpresent": {
     "id": "19f8f15f-c93e-477c-9dc7-28e47f912a11"
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_in\n",
    "\n",
    "nb=NaiveBayes(classes)\n",
    "nb.train(traindata,trainlabels)\n",
    "assert_equal (nb.test(testdata).shape[0], testdata.shape[0])\n",
    "assert_in( type(nb.predict([\"ok\"])) , [str, np.string_, np.str, np.str_] , \"Predict should return a label \\\n",
    "                                                                                            not list or array\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "c4695c7d2b42d0e0570c50ab36361afd",
     "grade": true,
     "grade_id": "test_acc",
     "locked": true,
     "points": 3,
     "solution": false
    },
    "nbpresent": {
     "id": "53bdbfd8-6ac5-4b23-90c3-3a5b8fd3b26d"
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_greater\n",
    "\n",
    "nb=NaiveBayes(classes)\n",
    "nb.train(traindata,trainlabels)\n",
    "pclasses=nb.test(testdata)\n",
    "acc=np.sum(pclasses==testlabels)/float(testlabels.shape[0])\n",
    "assert_greater(acc, 0.77, \"Acc must be greater then 77% you are doing something wrong\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "268244e33988983787a2f3e3b8f6eba3",
     "grade": true,
     "grade_id": "test_classifier_responce",
     "locked": true,
     "points": 4,
     "solution": false
    },
    "nbpresent": {
     "id": "668b0568-9559-4192-a753-69c0c4a3a10b"
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_equal\n",
    "\n",
    "comment_pos = \"A nice movie, the case was good. Overall a perfect play\"\n",
    "comment_neg = \"A waste of time, cast was bad. a clear No!\"\n",
    "\n",
    "#generate training and testing data...\n",
    "tX=np.concatenate((posfiles,negfiles))\n",
    "X=files_to_strings(tX)\n",
    "X = X.reshape((X.shape[0], 1))\n",
    "\n",
    "plabels=['pos']*len(posfiles)\n",
    "nlabels=['neg']*len(posfiles)\n",
    "true_labels = np.concatenate((plabels,nlabels))\n",
    "inverted_labels = np.concatenate((nlabels,plabels))\n",
    "\n",
    "true_nb=NaiveBayes(classes)\n",
    "true_nb.train(X,true_labels)\n",
    "\n",
    "inverted_nb=NaiveBayes(classes)\n",
    "inverted_nb.train(X,inverted_labels)\n",
    "\n",
    "assert_equal( true_nb.predict(comment_pos.split()), \"pos\" )\n",
    "assert_equal( true_nb.predict(comment_neg.split()), \"neg\" )\n",
    "\n",
    "assert_equal( inverted_nb.predict(comment_pos.split()), \"neg\" )\n",
    "assert_equal( inverted_nb.predict(comment_neg.split()), \"pos\" )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6ed2148a-237f-4175-90e3-978fb2226cb3"
    }
   },
   "source": [
    "### Test Cells End"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "d784cff6-2bb6-4b11-8ff0-c62d0e6570a1"
    }
   },
   "source": [
    "# Cross Validation\n",
    "\n",
    "Now lets throw our methods to winds of different folds and measure their accuracy..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "9b84bf90-1d3a-476e-b843-d291e0569499"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CV data for 2 classes\n",
      "(1800, 1) (200, 1)\n",
      "(1800, 1) (200, 1)\n",
      "(1800, 1) (200, 1)\n",
      "(1800, 1) (200, 1)\n",
      "(1800, 1) (200, 1)\n",
      "(1800, 1) (200, 1)\n",
      "(1800, 1) (200, 1)\n",
      "(1800, 1) (200, 1)\n",
      "(1800, 1) (200, 1)\n",
      "(1800, 1) (200, 1)\n"
     ]
    }
   ],
   "source": [
    "#Now lets generate n-fold training and testing data...\n",
    "nfolds=10\n",
    "folds=t.generate_folds(X,labels,nfolds) # generate folds for \n",
    "for k in arange(len(folds)):\n",
    "    print folds[k][0].shape, folds[k][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "2dd99df9-c579-4990-aae1-88932a6e3af8"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Fold 1 Accuracy = 0.805\n",
      "[Info] Fold 2 Accuracy = 0.775\n",
      "[Info] Fold 3 Accuracy = 0.865\n",
      "[Info] Fold 4 Accuracy = 0.81\n",
      "[Info] Fold 5 Accuracy = 0.84\n",
      "[Info] Fold 6 Accuracy = 0.82\n",
      "[Info] Fold 7 Accuracy = 0.805\n",
      "[Info] Fold 8 Accuracy = 0.825\n",
      "[Info] Fold 9 Accuracy = 0.8\n",
      "[Info] Fold 10 Accuracy = 0.78\n",
      "[0.80500000000000005, 0.77500000000000002, 0.86499999999999999, 0.81000000000000005, 0.83999999999999997, 0.81999999999999995, 0.80500000000000005, 0.82499999999999996, 0.80000000000000004, 0.78000000000000003]\n",
      "[Info] Mean Accuracy = 0.8125\n"
     ]
    }
   ],
   "source": [
    "totacc=[]\n",
    "#train a classifier for each fold...\n",
    "classes=np.unique(labels)\n",
    "\n",
    "for k in range(nfolds):\n",
    "    nb=NaiveBayes(classes)\n",
    "    \n",
    "    traindata=folds[k][0]\n",
    "    trainlabels=folds[k][1]\n",
    "    \n",
    "    #Lets first train the classifier\n",
    "    nb.train(traindata,trainlabels)\n",
    "    \n",
    "    testdata=folds[k][2]\n",
    "    testlabels=folds[k][3]\n",
    "    \n",
    "    #Lets test the classifier\n",
    "    pclasses= nb.test(testdata)\n",
    "    \n",
    "    #print pclasses\n",
    "    acc=np.sum(pclasses==testlabels)/float(testlabels.shape[0])\n",
    "    print \"[Info] Fold {} Accuracy = {}\".format(k+1, acc)    \n",
    "    \n",
    "    totacc.append(acc)\n",
    "\n",
    "print totacc\n",
    "\n",
    "mean_acc = np.mean(totacc)\n",
    "print '[Info] Mean Accuracy =', mean_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "nbpresent": {
     "id": "9cf9b6ac-e6ce-4f8b-8b20-68d65ca5c0da"
    }
   },
   "source": [
    "# Excellent, now its time to go into real waters of Kaggle.\n",
    "\n",
    "\n",
    "You will be needed to create an account on the Kaggle and download the data for the competition [\"Bag of words meets bags of popcorn\"](https://www.kaggle.com/c/word2vec-nlp-tutorial/data).  Note that you will be only downloading the \"labeledTrainData.tsv\" and \"labeledTestData.tsv\".\n",
    "\n",
    "\n",
    "\"labeledTrainData.tsv\" will be used for training your model and thus have prespecified labels for each example review. \"labeledTestData.tsv\" will be used for testing your model and thus don't have prespecified labels for each example. You will predicting the label for each review and then uploading your result to Kaggle server which will be evaluating your model and will give score to your entry. You will report this score during your assignment submission.\n",
    "\n",
    "**[Caution]** Please note that Kaggle limits maximum number of evaluations per 24 hours to 5 to reduce the overfitting on the test set, so be careful and throughly test your model before submitting your entry to Kaggle server. \n",
    "\n",
    "Read the instructions on the Competition Page. Note you are not allowed to use any of the library except what we have learned during class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "c9d7ec6a-9885-4a82-bee7-fd1a7e3ccfbf"
    }
   },
   "outputs": [],
   "source": [
    "# read the data-set\n",
    "train=pd.read_csv('./tmp/labeledTrainData.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "7d573e43-e0cd-4000-b793-4f1cd19a3a6f"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.50001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment\n",
       "count  25000.00000\n",
       "mean       0.50000\n",
       "std        0.50001\n",
       "min        0.00000\n",
       "25%        0.00000\n",
       "50%        0.50000\n",
       "75%        1.00000\n",
       "max        1.00000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "b354a4ff-dd9f-4559-bd10-fef096a853e5"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "00b8a356-42a0-4c61-9708-1dbfb8c45069"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "Yt=train['sentiment']\n",
    "Xt=train['review']\n",
    "Xt=np.array(Xt)\n",
    "Yt=np.array(Yt)\n",
    "\n",
    "print Xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "521c2512-6259-43e0-abcd-6cdf22eaa1ad"
    }
   },
   "outputs": [],
   "source": [
    "#read test set...\n",
    "test=pd.read_csv('./tmp/testData.tsv',sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "ca4d7fa8-c49e-475d-971c-370f2c785564"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12311_10</td>\n",
       "      <td>Naturally in a film who's main themes are of m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8348_2</td>\n",
       "      <td>This movie is a disaster within a disaster fil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5828_4</td>\n",
       "      <td>All in all, this is a movie for kids. We saw i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7186_2</td>\n",
       "      <td>Afraid of the Dark left me with the impression...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12128_7</td>\n",
       "      <td>A very accurate depiction of small time mob li...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                             review\n",
       "0  12311_10  Naturally in a film who's main themes are of m...\n",
       "1    8348_2  This movie is a disaster within a disaster fil...\n",
       "2    5828_4  All in all, this is a movie for kids. We saw i...\n",
       "3    7186_2  Afraid of the Dark left me with the impression...\n",
       "4   12128_7  A very accurate depiction of small time mob li..."
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5a4f48c5-79fb-4ca7-aca5-86f7539beb69"
    }
   },
   "source": [
    "#### Training Time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "560d69ba70bb62a18e317665c5058abe",
     "grade": false,
     "grade_id": "kaggle_cell_1",
     "locked": true,
     "solution": false
    },
    "nbpresent": {
     "id": "c79a9020-64c5-470f-963f-f2a1ebc4e79d"
    }
   },
   "outputs": [],
   "source": [
    "# Let's split the training data into two halves and test our accuracy...\n",
    "traindata,trainlabels,testdata,testlabels=t.split_data(Xt.reshape((Xt.shape[0],1)),Yt)\n",
    "classes=np.unique(trainlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "65200523b8bf7de2418ba0de0fb987c6",
     "grade": false,
     "grade_id": "kaggle_cell_2",
     "locked": true,
     "solution": false
    },
    "nbpresent": {
     "id": "16dc328c-a30d-4f07-b9d9-633a71afb821"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] training a classifier for following classes 0, 1\n",
      "[Info] Accuracy = 0.845066666667\n"
     ]
    }
   ],
   "source": [
    "# Now lets go and train the model and see its performance...\n",
    "print '[Info] training a classifier for following classes {}, {}'.format(classes[0],classes[1])\n",
    "nb=NaiveBayes(classes)\n",
    "nb.train(traindata,trainlabels)\n",
    "pclasses=nb.test(testdata)\n",
    "acc=np.sum(pclasses==testlabels)/float(testlabels.shape[0])\n",
    "print \"[Info] Accuracy = {}\".format(acc) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "8d552797-2eef-4e38-bdac-38aa1c980c14"
    }
   },
   "source": [
    "#### Cross-Validation Time..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "e3f8832c8d5c5aec3a4686f9cf13bf5a",
     "grade": false,
     "grade_id": "kaggle_cell_3",
     "locked": true,
     "solution": false
    },
    "nbpresent": {
     "id": "79443e83-ec18-4658-a22c-e69b7d6fe946"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating CV data for 2 classes\n",
      "(22500, 1) (2500, 1)\n",
      "(22500, 1) (2500, 1)\n",
      "(22500, 1) (2500, 1)\n",
      "(22500, 1) (2500, 1)\n",
      "(22500, 1) (2500, 1)\n",
      "(22500, 1) (2500, 1)\n",
      "(22500, 1) (2500, 1)\n",
      "(22500, 1) (2500, 1)\n",
      "(22500, 1) (2500, 1)\n",
      "(22500, 1) (2500, 1)\n"
     ]
    }
   ],
   "source": [
    "#Split the training data into 10 folds and test classifiers performance...\n",
    "\n",
    "nfolds=10\n",
    "folds=t.generate_folds(Xt.reshape((Xt.shape[0],1)),Yt,nfolds) # generate folds for \n",
    "for k in arange(len(folds)):\n",
    "    print folds[k][0].shape, folds[k][2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "85c038543210c9d4b02762be14730d9b",
     "grade": false,
     "grade_id": "kaggle_cell_4",
     "locked": true,
     "solution": false
    },
    "nbpresent": {
     "id": "e39ae5b9-e11e-4a4a-b9b2-3da0bbbbd700"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Fold 1 Accuracy = 0.8408\n",
      "[Info] Fold 2 Accuracy = 0.8348\n",
      "[Info] Fold 3 Accuracy = 0.8464\n",
      "[Info] Fold 4 Accuracy = 0.8444\n",
      "[Info] Fold 5 Accuracy = 0.8452\n",
      "[Info] Fold 6 Accuracy = 0.8612\n",
      "[Info] Fold 7 Accuracy = 0.8512\n",
      "[Info] Fold 8 Accuracy = 0.8436\n",
      "[Info] Fold 9 Accuracy = 0.8472\n",
      "[Info] Fold 10 Accuracy = 0.83\n",
      "[0.84079999999999999, 0.83479999999999999, 0.84640000000000004, 0.84440000000000004, 0.84519999999999995, 0.86119999999999997, 0.85119999999999996, 0.84360000000000002, 0.84719999999999995, 0.82999999999999996]\n",
      "[Info] Mean Accuracy = 0.84448\n"
     ]
    }
   ],
   "source": [
    "# As it takes time, so becareful it can cause your machine into red hot oven\n",
    "totacc=[]\n",
    "classes=np.unique(Yt)\n",
    "\n",
    "for k in range(nfolds):\n",
    "    nb=NaiveBayes(classes)\n",
    "    \n",
    "    traindata=folds[k][0]\n",
    "    trainlabels=folds[k][1]\n",
    "    \n",
    "    #Lets first train the classifier\n",
    "    nb.train(traindata,trainlabels)\n",
    "    \n",
    "    testdata=folds[k][2]\n",
    "    testlabels=folds[k][3]\n",
    "    \n",
    "    #Lets test the classifier\n",
    "    pclasses= nb.test(testdata)\n",
    "    \n",
    "    acc=np.sum(pclasses==testlabels)/float(testlabels.shape[0])\n",
    "    print \"[Info] Fold {} Accuracy = {}\".format(k+1, acc)    \n",
    "    \n",
    "    totacc.append(acc)\n",
    "\n",
    "print totacc\n",
    "print '[Info] Mean Accuracy =', np.mean(totacc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "c870260b-7d9d-446e-9f1b-06763ededaa6"
    }
   },
   "source": [
    "# Now let's train on the complete dataset and test on the provided test set..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "nbgrader": {
     "checksum": "c27687a3a83576b5360a0e383909305f",
     "grade": false,
     "grade_id": "kaggle_cell_5",
     "locked": true,
     "solution": false
    },
    "nbpresent": {
     "id": "0d9bab6f-19cb-481b-b27e-7e4551f7f82c"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training a Classifier on Full training set with classes = [0 1]\n"
     ]
    }
   ],
   "source": [
    "classes= np.unique(Yt)\n",
    "print 'Training a Classifier on Full training set with classes =', classes\n",
    "nb=NaiveBayes(classes)\n",
    "nb.train(Xt.reshape(Xt.shape[0],1),Yt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "2df4444c4b4fcbde8568ffea728d5658",
     "grade": false,
     "grade_id": "kaggle_cell_6",
     "locked": true,
     "solution": false
    },
    "nbpresent": {
     "id": "990c4e2f-1458-4968-b286-a39b1e84a6ea"
    }
   },
   "outputs": [],
   "source": [
    "#Get the test data...\n",
    "Xtest=test['review']\n",
    "Xtest=np.array(Xtest.reshape((Xtest.shape[0],1)))\n",
    "#test the classifier on the provided test set...\n",
    "pclasses=nb.test(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "nbgrader": {
     "checksum": "a902480b291b88f6c9fb7422cd845305",
     "grade": false,
     "grade_id": "kaggle_cell_7",
     "locked": true,
     "solution": false
    },
    "nbpresent": {
     "id": "9ac99be5-b043-44a9-9726-3eac51a1dbc9"
    }
   },
   "outputs": [],
   "source": [
    "#write the result in the kaggle's required format\n",
    "output = pd.DataFrame( data={\"id\":test[\"id\"], \"sentiment\":pclasses} )\n",
    "\n",
    "# Use pandas to write the comma-separated output file\n",
    "output.to_csv( \"./tmp/Naive_bays_Bag_of_Words_model.csv\", index=False, quoting=3 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "5b5d4b95-94c4-4708-9895-60be4f4e9489"
    }
   },
   "source": [
    "# Time to Upload the prediction to Kaggle...\n",
    "\n",
    "Now upload the result on the Kaggle and see your ranking and score. Using this simple method you can have an accuracy of around 0.80960."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "f4ea170b-8971-48d7-98c9-68fecbe316c3"
    }
   },
   "source": [
    "# Improvement by Excluding Stop Words...\n",
    "\n",
    "You can improve your score further by excluding the commonly occuring words (also known as stop words) in the English language.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "4bb12c37-bec9-4b76-8366-376aaaa2516a"
    }
   },
   "outputs": [],
   "source": [
    "#read and create a set of stop \n",
    "stopwords=set(t.read_txt_file('./data/english.stop'))\n",
    "print stopwords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "nbpresent": {
     "id": "ce5fa41a-4fca-41d2-bf0a-6b4f0b140dc2"
    }
   },
   "source": [
    "Now you can re-build the model by excluding these words and again upload your results on Kaggle. \n",
    "\n",
    "Doing this simple trick can further improve your accuracy to 0.81768.\n",
    "\n",
    "For final submission attach the screen-shot of the leader-board with your score\n",
    "\n",
    "Insert ScreenShot of Leader-board Below\n",
    "----------------------------------------\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "nbpresent": {
   "slides": {
    "5fd35671-1b62-45d3-999b-42e56e9d5357": {
     "id": "5fd35671-1b62-45d3-999b-42e56e9d5357",
     "prev": null,
     "regions": {
      "5206d1d2-623f-4f1c-96ee-fcc9d611b796": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "0721764a-2ee0-45f9-b8d0-3584e88fce70",
        "part": "whole"
       },
       "id": "5206d1d2-623f-4f1c-96ee-fcc9d611b796"
      }
     }
    },
    "7eb26445-5337-4d16-a94e-c7853cde2f59": {
     "id": "7eb26445-5337-4d16-a94e-c7853cde2f59",
     "prev": "a583b2c2-8b53-436d-8ad8-67af1790ac98",
     "regions": {
      "1c47794f-5f2e-461b-a98a-05baad93bd6e": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "40627bd6-9415-4f97-bf2b-e24b1371cd62",
        "part": "whole"
       },
       "id": "1c47794f-5f2e-461b-a98a-05baad93bd6e"
      },
      "d12aa0ee-4f90-4631-a3ec-da2edbfe22b8": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "5753b5c5-90b7-4a3c-ab3d-cbcb4d956e22",
        "part": "whole"
       },
       "id": "d12aa0ee-4f90-4631-a3ec-da2edbfe22b8"
      }
     }
    },
    "8cd73125-6204-432e-92d9-1bc0dff1272a": {
     "id": "8cd73125-6204-432e-92d9-1bc0dff1272a",
     "prev": "7eb26445-5337-4d16-a94e-c7853cde2f59",
     "regions": {
      "03660ea9-4e97-4925-bc12-13a87d2d6e9c": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "4bb12c37-bec9-4b76-8366-376aaaa2516a",
        "part": "whole"
       },
       "id": "03660ea9-4e97-4925-bc12-13a87d2d6e9c"
      },
      "040d37bb-864d-41e9-b65d-c41c27d4b7dc": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "9cf9b6ac-e6ce-4f8b-8b20-68d65ca5c0da",
        "part": "whole"
       },
       "id": "040d37bb-864d-41e9-b65d-c41c27d4b7dc"
      },
      "07571794-5fb4-4538-bb34-4800e1cec2e7": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "990c4e2f-1458-4968-b286-a39b1e84a6ea",
        "part": "whole"
       },
       "id": "07571794-5fb4-4538-bb34-4800e1cec2e7"
      },
      "0aa7d62f-0eb8-404f-923f-841fa3990453": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "f4ea170b-8971-48d7-98c9-68fecbe316c3",
        "part": "whole"
       },
       "id": "0aa7d62f-0eb8-404f-923f-841fa3990453"
      },
      "0b837dc6-a96a-45f9-8e16-67e9ac5404f9": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "53bdbfd8-6ac5-4b23-90c3-3a5b8fd3b26d",
        "part": "whole"
       },
       "id": "0b837dc6-a96a-45f9-8e16-67e9ac5404f9"
      },
      "0d1bcedf-97b5-48d3-b454-a11e74fabbb1": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "00b8a356-42a0-4c61-9708-1dbfb8c45069",
        "part": "whole"
       },
       "id": "0d1bcedf-97b5-48d3-b454-a11e74fabbb1"
      },
      "0e30159a-3dff-40f1-be4a-4afd26c1366d": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "ca4d7fa8-c49e-475d-971c-370f2c785564",
        "part": "whole"
       },
       "id": "0e30159a-3dff-40f1-be4a-4afd26c1366d"
      },
      "13d3e549-5f36-4ea7-aff1-7bd07aa412ff": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "16dc328c-a30d-4f07-b9d9-633a71afb821",
        "part": "whole"
       },
       "id": "13d3e549-5f36-4ea7-aff1-7bd07aa412ff"
      },
      "1e094a02-fd08-4410-a33f-5416ba7ca7d8": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "19f8f15f-c93e-477c-9dc7-28e47f912a11",
        "part": "whole"
       },
       "id": "1e094a02-fd08-4410-a33f-5416ba7ca7d8"
      },
      "27bd6642-db88-459c-b707-dbfdf1bf2d70": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "c870260b-7d9d-446e-9f1b-06763ededaa6",
        "part": "whole"
       },
       "id": "27bd6642-db88-459c-b707-dbfdf1bf2d70"
      },
      "286e8abe-05ba-4983-a6df-2df25a954f73": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "2ac1545d-a0c3-4b0f-87fe-ac7c523d34f5",
        "part": "whole"
       },
       "id": "286e8abe-05ba-4983-a6df-2df25a954f73"
      },
      "2dbb7c6b-2977-4274-abe0-0906e76dd377": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "7d573e43-e0cd-4000-b793-4f1cd19a3a6f",
        "part": "whole"
       },
       "id": "2dbb7c6b-2977-4274-abe0-0906e76dd377"
      },
      "3778c350-d848-4fac-be9e-4e5f269021c8": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "c9d7ec6a-9885-4a82-bee7-fd1a7e3ccfbf",
        "part": "whole"
       },
       "id": "3778c350-d848-4fac-be9e-4e5f269021c8"
      },
      "37e1cb71-dd48-4894-b5d4-0ca5fbb7ff2f": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "6ed2148a-237f-4175-90e3-978fb2226cb3",
        "part": "whole"
       },
       "id": "37e1cb71-dd48-4894-b5d4-0ca5fbb7ff2f"
      },
      "4d797538-7a34-4b73-8f76-7e7513a71423": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "d784cff6-2bb6-4b11-8ff0-c62d0e6570a1",
        "part": "whole"
       },
       "id": "4d797538-7a34-4b73-8f76-7e7513a71423"
      },
      "5a1b1eab-4209-4c95-8bcc-f766e6912e83": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "668b0568-9559-4192-a753-69c0c4a3a10b",
        "part": "whole"
       },
       "id": "5a1b1eab-4209-4c95-8bcc-f766e6912e83"
      },
      "606feb72-4818-471c-b4b7-f497d936635f": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "8d552797-2eef-4e38-bdac-38aa1c980c14",
        "part": "whole"
       },
       "id": "606feb72-4818-471c-b4b7-f497d936635f"
      },
      "6e0c6394-b7bf-4dc0-bc9c-b00cb7ca42d4": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "0d9bab6f-19cb-481b-b27e-7e4551f7f82c",
        "part": "whole"
       },
       "id": "6e0c6394-b7bf-4dc0-bc9c-b00cb7ca42d4"
      },
      "794213e7-db51-4b2e-8b7a-9dded7b8a2ce": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "fcb102ee-6dcd-4b84-9fed-3bfc4cb7bc9d",
        "part": "whole"
       },
       "id": "794213e7-db51-4b2e-8b7a-9dded7b8a2ce"
      },
      "88c005ff-5c41-4aaa-8884-011e3f82f6df": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "e39ae5b9-e11e-4a4a-b9b2-3da0bbbbd700",
        "part": "whole"
       },
       "id": "88c005ff-5c41-4aaa-8884-011e3f82f6df"
      },
      "89268c03-8d34-4318-b939-dce74662263a": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "9ac99be5-b043-44a9-9726-3eac51a1dbc9",
        "part": "whole"
       },
       "id": "89268c03-8d34-4318-b939-dce74662263a"
      },
      "9bee0402-9cbc-4d52-84b9-5a10b85a3654": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "c79a9020-64c5-470f-963f-f2a1ebc4e79d",
        "part": "whole"
       },
       "id": "9bee0402-9cbc-4d52-84b9-5a10b85a3654"
      },
      "9dfd08b9-f4c3-4945-9910-fb27f5eae16e": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "5b5d4b95-94c4-4708-9895-60be4f4e9489",
        "part": "whole"
       },
       "id": "9dfd08b9-f4c3-4945-9910-fb27f5eae16e"
      },
      "b3089076-73a2-4531-b593-2d049342571e": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "79443e83-ec18-4658-a22c-e69b7d6fe946",
        "part": "whole"
       },
       "id": "b3089076-73a2-4531-b593-2d049342571e"
      },
      "b4a18719-70be-468f-853f-e1fc8c2b2883": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "521c2512-6259-43e0-abcd-6cdf22eaa1ad",
        "part": "whole"
       },
       "id": "b4a18719-70be-468f-853f-e1fc8c2b2883"
      },
      "b52a2ba8-3632-488c-85f1-3eba57493c67": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "1d77d1b6-b8e0-4c09-a484-27ff7c1ae1f6",
        "part": "whole"
       },
       "id": "b52a2ba8-3632-488c-85f1-3eba57493c67"
      },
      "bb9a5145-ff84-4a41-936a-b9721d74a580": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "5a4f48c5-79fb-4ca7-aca5-86f7539beb69",
        "part": "whole"
       },
       "id": "bb9a5145-ff84-4a41-936a-b9721d74a580"
      },
      "cd35564e-243c-45ab-94b7-f54db7121234": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "2dd99df9-c579-4990-aae1-88932a6e3af8",
        "part": "whole"
       },
       "id": "cd35564e-243c-45ab-94b7-f54db7121234"
      },
      "d5ccbc32-5613-4440-8fdd-48c5067a823a": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "244a98fd-7f59-4e40-b26a-9b7cdb766940",
        "part": "whole"
       },
       "id": "d5ccbc32-5613-4440-8fdd-48c5067a823a"
      },
      "db9ecb20-3e26-401a-9835-9a429c74ea61": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "b354a4ff-dd9f-4559-bd10-fef096a853e5",
        "part": "whole"
       },
       "id": "db9ecb20-3e26-401a-9835-9a429c74ea61"
      },
      "e66c241d-b99a-4890-bffd-5deaf42c4701": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "aee3ce96-c88a-4bc5-bc9f-aa58c355db55",
        "part": "whole"
       },
       "id": "e66c241d-b99a-4890-bffd-5deaf42c4701"
      },
      "f4d4cf4c-9547-4a8e-b478-e41df9d65ffb": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "ce5fa41a-4fca-41d2-bf0a-6b4f0b140dc2",
        "part": "whole"
       },
       "id": "f4d4cf4c-9547-4a8e-b478-e41df9d65ffb"
      },
      "fce43b11-e564-42aa-aceb-9f2ce61e0721": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "9b84bf90-1d3a-476e-b843-d291e0569499",
        "part": "whole"
       },
       "id": "fce43b11-e564-42aa-aceb-9f2ce61e0721"
      }
     }
    },
    "a583b2c2-8b53-436d-8ad8-67af1790ac98": {
     "id": "a583b2c2-8b53-436d-8ad8-67af1790ac98",
     "prev": "5fd35671-1b62-45d3-999b-42e56e9d5357",
     "regions": {
      "27c4b166-02a8-414c-88d7-f0c720fc93aa": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.11,
        "y": 0.5
       },
       "content": {
        "cell": "8bfc4479-732e-4713-865c-6b358e0fe8da",
        "part": "whole"
       },
       "id": "27c4b166-02a8-414c-88d7-f0c720fc93aa"
      },
      "3bd0f73b-208f-4c49-9f8c-8e110949a684": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "0b1f3428-37ea-401c-9556-627e53402501",
        "part": "whole"
       },
       "id": "3bd0f73b-208f-4c49-9f8c-8e110949a684"
      },
      "5d83b9ab-3c03-4a92-a479-ccc091305d38": {
       "attrs": {
        "height": 0.8,
        "width": 0.8,
        "x": 0.1,
        "y": 0.1
       },
       "content": {
        "cell": "33b0fb9a-4940-4251-9a82-44562ed9724d",
        "part": "whole"
       },
       "id": "5d83b9ab-3c03-4a92-a479-ccc091305d38"
      },
      "b7bac14c-7c30-4d47-add5-537f1f89a9f7": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "c7a1f399-97ec-4a5d-b8b0-c20a136f93b8",
        "part": "whole"
       },
       "id": "b7bac14c-7c30-4d47-add5-537f1f89a9f7"
      },
      "e5378ca9-d48e-424c-bc6d-c4272fab97b9": {
       "attrs": {
        "height": 0.4,
        "width": 0.8,
        "x": 0.1,
        "y": 0.5
       },
       "content": {
        "cell": "f4da4af7-6a5c-4674-a694-6097610f7271",
        "part": "whole"
       },
       "id": "e5378ca9-d48e-424c-bc6d-c4272fab97b9"
      }
     }
    }
   },
   "themes": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
